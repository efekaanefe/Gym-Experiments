{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38] [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "print(env.observation_space.low, env.observation_space.high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.4    -4.     -0.2099 -4.    ] [2.4    4.     0.2099 4.    ]\n"
     ]
    }
   ],
   "source": [
    "max_obs_values = np.array([2.4, 4, 0.2099 , 4])\n",
    "min_obs_values = np.array([-2.4, -4, -0.2099, -4])\n",
    "print(min_obs_values, max_obs_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISCRETE_OBS_SPACE_SIZE = [10]* len(max_obs_values) # these are the what the max values will corresponds to\n",
    "discrete_obs_space_step_size = (max_obs_values - min_obs_values) / DISCRETE_OBS_SPACE_SIZE\n",
    "\n",
    "def discretizer(obs):\n",
    "    # obs = np.array([obs[0], obs[2]])\n",
    "    discrete_obs = (obs - min_obs_values-0.1)/discrete_obs_space_step_size\n",
    "    return tuple(discrete_obs.astype(np.int16)) # tuple to make indexing easier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.1\n",
    "DISCOUNT = 0.99\n",
    "EXPLORATION_RATE = 1\n",
    "EXPLORATION_DECAY_RATE = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 10, 10, 2)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table = np.zeros(DISCRETE_OBS_SPACE_SIZE + [env.action_space.n])\n",
    "q_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0.]\n",
      "[0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(q_table[0][0][0][0])\n",
    "print(q_table[(0,0,0,0)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.4    -4.     -0.2099 -4.    ] [2.4    4.     0.2099 4.    ]\n",
      "[ 0.02870877 -0.03970408  0.04015733 -0.00687193]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5, 4, 5, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation, info = env.reset()\n",
    "# obs = np.array([observation[0], observation[2]])\n",
    "obs = observation\n",
    "print(min_obs_values, max_obs_values)\n",
    "print(obs)\n",
    "discrete_obs = (obs - min_obs_values)/discrete_obs_space_step_size\n",
    "discrete_obs = tuple(discrete_obs.astype(np.int16))\n",
    "discrete_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "total_count = 0\n",
    "non_zero_count = 0\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        for k in range(10):\n",
    "            for l in range(10):\n",
    "                probility = q_table[(i,j,k,l)]\n",
    "                if np.count_nonzero(probility) != 0:\n",
    "                    # print(probility)\n",
    "                    non_zero_count += 1\n",
    "                total_count += 1\n",
    "print(non_zero_count/total_count) # it doesn't even see most of the observation combinations\n",
    "# 0.1793 max i have seen for 10 discrete value for feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0.]\n"
     ]
    }
   ],
   "source": [
    "action = 1\n",
    "discrete_obs = (4, 5, 1, 3)\n",
    "print(q_table[discrete_obs])\n",
    "\n",
    "# q_table[discrete_obs + (action,)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, exploration rate 0.4500100000022255, avg. score 95.78\n",
      "Episode 1000, exploration rate 0.4400100000022155, avg. score 99.44\n",
      "Episode 2000, exploration rate 0.4300100000022055, avg. score 113.04\n",
      "Episode 3000, exploration rate 0.4200100000021955, avg. score 112.37\n",
      "Episode 4000, exploration rate 0.4100100000021855, avg. score 133.73\n",
      "Episode 5000, exploration rate 0.4000100000021755, avg. score 126.86\n",
      "Episode 6000, exploration rate 0.3900100000021655, avg. score 124.28\n",
      "Episode 7000, exploration rate 0.3800100000021555, avg. score 153.15\n",
      "Episode 8000, exploration rate 0.3700100000021455, avg. score 138.07\n",
      "Episode 9000, exploration rate 0.3600100000021355, avg. score 149.19\n",
      "Episode 10000, exploration rate 0.3500100000021255, avg. score 154.69\n",
      "Episode 11000, exploration rate 0.3400100000021155, avg. score 109.43\n",
      "Episode 12000, exploration rate 0.3300100000021055, avg. score 174.94\n",
      "Episode 13000, exploration rate 0.3200100000020955, avg. score 159.56\n",
      "Episode 14000, exploration rate 0.3100100000020855, avg. score 209.3\n",
      "Episode 15000, exploration rate 0.3000100000020755, avg. score 175.3\n",
      "Episode 16000, exploration rate 0.2900100000020655, avg. score 181.7\n",
      "Episode 17000, exploration rate 0.2800100000020555, avg. score 196.85\n",
      "Episode 18000, exploration rate 0.2700100000020455, avg. score 206.39\n",
      "Episode 19000, exploration rate 0.2600100000020355, avg. score 220.4\n",
      "Episode 20000, exploration rate 0.2500100000020255, avg. score 159.25\n",
      "Episode 21000, exploration rate 0.2400100000020155, avg. score 221.71\n",
      "Episode 22000, exploration rate 0.2300100000020055, avg. score 194.85\n",
      "Episode 23000, exploration rate 0.2200100000019955, avg. score 199.2\n",
      "Episode 24000, exploration rate 0.2100100000019855, avg. score 198.53\n",
      "Episode 25000, exploration rate 0.2000100000019755, avg. score 253.91\n",
      "Episode 26000, exploration rate 0.1900100000019655, avg. score 321.78\n",
      "Episode 27000, exploration rate 0.1800100000019555, avg. score 217.82\n",
      "Episode 28000, exploration rate 0.1700100000019455, avg. score 180.08\n",
      "Episode 29000, exploration rate 0.1600100000019355, avg. score 270.7\n",
      "Episode 30000, exploration rate 0.1500100000019255, avg. score 236.55\n",
      "Episode 31000, exploration rate 0.1400100000019155, avg. score 250.61\n",
      "Episode 32000, exploration rate 0.1300100000019055, avg. score 253.15\n",
      "Episode 33000, exploration rate 0.12001000000190241, avg. score 326.95\n",
      "Episode 34000, exploration rate 0.11001000000190629, avg. score 280.31\n",
      "Episode 35000, exploration rate 0.10001000000191017, avg. score 383.56\n",
      "Episode 36000, exploration rate 0.09001000000191405, avg. score 593.48\n",
      "Episode 37000, exploration rate 0.08001000000191792, avg. score 694.28\n",
      "Episode 38000, exploration rate 0.0700100000019218, avg. score 278.61\n",
      "Episode 39000, exploration rate 0.06001000000192395, avg. score 550.87\n",
      "Episode 40000, exploration rate 0.050010000001920886, avg. score 575.0\n",
      "Episode 41000, exploration rate 0.040010000001917824, avg. score 1686.51\n",
      "Episode 42000, exploration rate 0.030010000001915192, avg. score 386.84\n",
      "Episode 43000, exploration rate 0.0200100000019156, avg. score 428.07\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 100000\n",
    "for e in range(num_episodes):\n",
    "    state, _ = env.reset()\n",
    "    done = False; score_per_episode = 0\n",
    "    while not done:\n",
    "        discrete_state = discretizer(state) \n",
    "        action = np.argmax(q_table[discrete_state])\n",
    "        if EXPLORATION_RATE > np.random.random():\n",
    "             action = env.action_space.sample() \n",
    "        new_state, reward, done, _, _ = env.step(action)\n",
    "        new_discrete_state = discretizer(new_state)\n",
    "        # print(state, discrete_state, action)\n",
    "        reward = 1 if not done else -1\n",
    "        \n",
    "        max_future_q = np.max(q_table[new_discrete_state])\n",
    "        current_q = q_table[discrete_state + (action,)]\n",
    "        new_q = (1-LEARNING_RATE) * current_q + LEARNING_RATE * (reward + DISCOUNT * max_future_q)\n",
    "        q_table[discrete_state + (action,)] = new_q\n",
    "     \n",
    "        state = new_state\n",
    "        score_per_episode += reward\n",
    "        \n",
    "    # if e > num_episodes/2:\n",
    "    EXPLORATION_RATE = max(EXPLORATION_RATE - EXPLORATION_DECAY_RATE, 0)\n",
    "    scores.append(score_per_episode)\n",
    "    if e % 1000 == 0:\n",
    "        print(f\"Episode {e}, exploration rate {EXPLORATION_RATE}, avg. score {np.mean(scores[-100:])}\")\n",
    "    # if score_per_episode > 2000:\n",
    "    #     break\n",
    "        \n",
    "env.close()\n",
    "\n",
    "# discrete state values are not really changing much\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 1000\n",
    "num_windows = len(scores) // window_size\n",
    "smoothed_scores = [np.mean(scores[i*window_size:(i+1)*window_size]) for i in range(num_windows)]\n",
    "plt.plot(smoothed_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
